{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMLmm1iZap1q2IOSiTe3kR5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ElqA8WMzOcg8","executionInfo":{"status":"ok","timestamp":1687974495599,"user_tz":-60,"elapsed":1255,"user":{"displayName":"Ashwin Kashyap","userId":"16952148365127114775"}},"outputId":"0be8f110-20aa-4858-d869-25309e341148"},"outputs":[{"output_type":"stream","name":"stdout","text":["(438, 571, 3)\n","(371, 482, 3)\n","(315, 408, 3)\n","(269, 346, 3)\n","(230, 295, 3)\n","(198, 252, 3)\n","(171, 216, 3)\n","--------\n","(438, 571, 3)\n","(371, 482, 3)\n","(315, 408, 3)\n","(269, 346, 3)\n","(230, 295, 3)\n","(198, 252, 3)\n","(171, 216, 3)\n"]}],"source":["import os\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import csv\n","\n","# File path for the CSV file\n","output_csv_file = '/Users/ashwinkashyap/Downloads/output_dataset.csv'\n","\n","nlevels = 8\n","scaleFactor = 1.2\n","EDGE_THRESHOLD = 19\n","PATCH_SIZE = 31\n","mvScaleFactor = [None] * nlevels\n","\n","mvScaleFactor[0] = 1.0\n","\n","for i in range(1, nlevels):\n","    mvScaleFactor[i]=mvScaleFactor[i-1]*scaleFactor\n","\n","# create SIFT feature extractor\n","sift = cv2.SIFT_create()\n","\n","#def compute_features_pp(filename, dnfname):\n","def compute_features_pp(filename):\n","    image = cv2.imread(filename)\n","    # Initialize mvImagePyramid\n","    mvImagePyramid = [None] * nlevels\n","\n","    for level in range(0, nlevels):\n","        if level == 0:\n","            mvImagePyramid[0] = cv2.copyMakeBorder(image, EDGE_THRESHOLD, EDGE_THRESHOLD, EDGE_THRESHOLD, EDGE_THRESHOLD,\n","                                           cv2.BORDER_REFLECT_101)\n","        else:\n","            scale = scaleFactor ** level\n","            sz = (int(image.shape[1] / scale), int(image.shape[0] / scale))\n","            resized = cv2.resize(mvImagePyramid[level-1], sz, interpolation=cv2.INTER_LINEAR)\n","            mvImagePyramid[level] = cv2.copyMakeBorder(resized, EDGE_THRESHOLD, EDGE_THRESHOLD, EDGE_THRESHOLD, EDGE_THRESHOLD,\n","                                                   cv2.BORDER_REFLECT_101 + cv2.BORDER_ISOLATED)\n","            print(mvImagePyramid[level].shape)\n","\n","        # detect features from the image\n","        keypoints, descriptors = sift.detectAndCompute(mvImagePyramid[level], None)\n","\n","\n","        for keypoint in keypoints:\n","            keypoint.octave = level\n","            keypoint.size = PATCH_SIZE*mvScaleFactor[level]\n","            keypoint.response = round(keypoint.response * 1000)\n","'''\n","            # Open the CSV file in write mode\n","            with open(output_csv_file, 'a', newline='') as file:\n","                # Create a CSV writer object\n","                writer = csv.writer(file)\n","                # Write the data to the CSV file\n","                row = [str(val) for val in [filename, round(keypoint.pt[0]), round(keypoint.pt[1]), keypoint.size, keypoint.angle, keypoint.response, keypoint.octave, keypoint.class_id]]\n","                writer.writerow(row)\n","'''\n","\n","\"\"\"\n","# Specify the directory path\n","directory = \"/Users/ashwinkashyap/Dissertation/Code/rgbd_dataset_freiburg1_floor/rgb\"\n","\n","# Iterate through the directory\n","for filename in os.listdir(directory):\n","    if filename.endswith(\".txt\"):\n","      with open(filename, 'r') as file:\n","        line = file.read\n","    # Check if the file has an image extension\n","    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n","        rgb_folder = rgb_directory+'/'+filename\n","        depth_folder = depth_directory+'/'+\n","        compute_features_pp(filename, dnfname)\n","print(f\"Data has been written to '{output_csv_file}'.\")\n","\"\"\"\n","\n","compute_features_pp('d.pgm')\n","print('--------')\n","compute_features_pp('r.ppm')"]},{"cell_type":"code","source":["with open('/cs/home/akhkr1/cuda-ubuntu/tum_dataset/tum_synched.txt')\n","for line in file:\n","        parts = line.strip().split(' ')\n","        rgb_filename = parts[1]\n","        depth_filename = parts[2]\n","        print(\"RGB filename:\", rgb_filename)\n","        print(\"Depth filename:\", depth_filename)"],"metadata":{"id":"5yG0xsbcXRAb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","\n","image = cv2.imread('d.pgm')\n","image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","print(image)\n","print(image[0,2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EIT5oJ8C9J_R","executionInfo":{"status":"ok","timestamp":1687972288025,"user_tz":-60,"elapsed":309,"user":{"displayName":"Ashwin Kashyap","userId":"16952148365127114775"}},"outputId":"64db8bd5-a11d-4fe8-a46d-e31c428025e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[194 194 195 ... 255 255 255]\n"," [194 194 195 ... 255 255 255]\n"," [194 194 195 ... 255 255 255]\n"," ...\n"," [162 162 163 ... 255 255 255]\n"," [162 163 163 ... 255 255 255]\n"," [162 163 163 ... 255 255 255]]\n","195\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import csv\n","from google.colab.patches import cv2_imshow\n","from PIL import Image\n","import torch\n","import torchvision.transforms as T\n","\n","\n","dinov2_vitl14 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitl14')\n","\n","# Load and preprocess the input image\n","transform = T.Compose([\n","    T.Resize(224),\n","    T.CenterCrop(224),\n","    T.ToTensor(),\n","    T.Normalize(mean=[0.5], std=[0.5]),\n","])\n","# File path for the CSV file\n","output_csv_file = '/Users/ashwinkashyap/Downloads/output_dataset.csv'\n","\n","nlevels = 8\n","scaleFactor = 1.2\n","EDGE_THRESHOLD = 19\n","PATCH_SIZE = 31\n","mvScaleFactor = [None] * nlevels\n","\n","mvScaleFactor[0] = 1.0\n","\n","for i in range(1, nlevels):\n","    mvScaleFactor[i]=mvScaleFactor[i-1]*scaleFactor\n","\n","# create SIFT feature extractor\n","sift = cv2.SIFT_create()\n","\n","#def compute_features_pp(filename, dnfname):\n","def compute_features_pp(filename):\n","    image = cv2.imread(filename)\n","    # Initialize mvImagePyramid\n","    mvImagePyramid = [None] * nlevels\n","\n","    for level in range(0, nlevels):\n","        if level == 0:\n","          mvImagePyramid[0] = cv2.copyMakeBorder(image, EDGE_THRESHOLD, EDGE_THRESHOLD, EDGE_THRESHOLD, EDGE_THRESHOLD,\n","                                           cv2.BORDER_REFLECT_101)\n","        else:\n","            scale = scaleFactor ** level\n","            sz = (int(image.shape[1] / scale), int(image.shape[0] / scale))\n","            resized = cv2.resize(mvImagePyramid[level-1], sz, interpolation=cv2.INTER_LINEAR)\n","            mvImagePyramid[level] = cv2.copyMakeBorder(resized, EDGE_THRESHOLD, EDGE_THRESHOLD, EDGE_THRESHOLD, EDGE_THRESHOLD,\n","                                                   cv2.BORDER_REFLECT_101 + cv2.BORDER_ISOLATED)\n","            print(mvImagePyramid[level].shape)\n","            temp = Image.fromarray(mvImagePyramid[level])\n","            temp = transform(temp).unsqueeze(0)\n","            with torch.no_grad():\n","              features = dinov2_vitl14.forward_features(temp)[\"x_norm_patchtokens\"]\n","              features = features.squeeze(0)\n","              print(features.shape)\n","        # detect features from the image\n","        keypoints, descriptors = sift.detectAndCompute(mvImagePyramid[level], None)\n","        sift_image = cv2.drawKeypoints(mvImagePyramid[level], keypoints, outImage=None)\n","        cv2_imshow(sift_image)\n","        print(len(keypoints))\n","\n","\n","    for keypoint in keypoints:\n","        #keypoint.octave = level\n","         keypoint.size = PATCH_SIZE*mvScaleFactor[0]\n","         keypoint.response = round(keypoint.response * 1000)\n","\n","\n","'''\n","            # Open the CSV file in write mode\n","            with open(output_csv_file, 'a', newline='') as file:\n","                # Create a CSV writer object\n","                writer = csv.writer(file)\n","                # Write the data to the CSV file\n","                row = [str(val) for val in [filename, round(keypoint.pt[0]), round(keypoint.pt[1]), keypoint.size, keypoint.angle, keypoint.response, keypoint.octave, keypoint.class_id]]\n","                writer.writerow(row)\n","'''\n","\n","\"\"\"\n","# Specify the directory path\n","directory = \"/Users/ashwinkashyap/Dissertation/Code/rgbd_dataset_freiburg1_floor/rgb\"\n","\n","# Iterate through the directory\n","for filename in os.listdir(directory):\n","    if filename.endswith(\".txt\"):\n","      with open(filename, 'r') as file:\n","        line = file.read\n","    # Check if the file has an image extension\n","    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n","        rgb_folder = rgb_directory+'/'+filename\n","        depth_folder = depth_directory+'/'+\n","        compute_features_pp(filename, dnfname)\n","print(f\"Data has been written to '{output_csv_file}'.\")\n","\"\"\"\n","\n","compute_features_pp('r.ppm')"],"metadata":{"id":"KhzRgiVk9lns","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1_Y4uccy6_TjrOfS1oVLmjk2I48mtEeRy"},"executionInfo":{"status":"ok","timestamp":1688064649409,"user_tz":-60,"elapsed":33104,"user":{"displayName":"Ashwin Kashyap","userId":"16952148365127114775"}},"outputId":"6549f4be-a8c0-41f3-8e83-95fb9cce9e3e"},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"bUo8lDAhwCjq"},"execution_count":null,"outputs":[]}]}
